import requests
import time

BASE_URL = "http://localhost:8000"
PROMPT = "What are the benefits of eating apples?"

def generate(label):
    print(f"\n--- {label} ---")
    start = time.time()
    payload = {"prompt": PROMPT, "max_tokens": 100}
    
    try:
        resp = requests.post(f"{BASE_URL}/generate", json=payload)
        duration = time.time() - start
        
        if resp.status_code == 200:
            data = resp.json()
            source = data.get('source', 'unknown')
            print(f"âœ… Status: 200 OK")
            print(f"ğŸ”Œ Source: {source}")
            print(f"â±ï¸  Time:   {duration:.4f}s")
            print(f"ğŸ“ Output: {data['response'][:60]}...")
            return source
        else:
            print(f"âŒ Error {resp.status_code}: {resp.text}")
            return "error"
    except Exception as e:
        print(f"âŒ Connection Error: {e}")
        return "error"

print(f"ğŸš€ TESTING SEMANTIC CACHE")

# 1. Cold Request
s1 = generate("Request 1 (Expecting GPU ğŸ¢)")

if s1 == "error":
    print("\nâš ï¸  Did you forget to load a model first? Run test_sprint1.py!")
    exit(1)

# 2. Wait a moment for Background Task to finish saving to DB
print("\n...waiting for background DB write...")
time.sleep(1) 

# 3. Warm Request
s2 = generate("Request 2 (Expecting CACHE âš¡)")

print("\n" + "="*30)
if s1.startswith("gpu") and s2.startswith("cache"):
    print("âœ… SUCCESS: Cache hit on second try!")
else:
    print("âŒ FAILURE: Caching did not work as expected.")